BEVFusion(
  (encoders): ModuleDict(
    (camera): ModuleDict(
      (backbone): SwinTransformer(
        (patch_embed): PatchEmbed(
          (adap_padding): AdaptivePadding()
          (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
          (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
        )
        (drop_after_pos): Dropout(p=0.0, inplace=False)
        (stages): ModuleList(
          (0): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=96, out_features=288, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=96, out_features=96, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=96, out_features=384, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=384, out_features=96, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=96, out_features=288, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=96, out_features=96, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=96, out_features=384, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=384, out_features=96, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
            (downsample): PatchMerging(
              (adap_padding): AdaptivePadding()
              (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
              (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (reduction): Linear(in_features=384, out_features=192, bias=False)
            )
          )
          (1): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=192, out_features=576, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=192, out_features=192, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=192, out_features=768, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=768, out_features=192, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=192, out_features=576, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=192, out_features=192, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=192, out_features=768, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=768, out_features=192, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
            (downsample): PatchMerging(
              (adap_padding): AdaptivePadding()
              (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (reduction): Linear(in_features=768, out_features=384, bias=False)
            )
          )
          (2): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (2): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (3): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (4): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (5): SwinBlock(
                (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=384, out_features=1152, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=384, out_features=384, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=384, out_features=1536, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=1536, out_features=384, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
            (downsample): PatchMerging(
              (adap_padding): AdaptivePadding()
              (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))
              (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
              (reduction): Linear(in_features=1536, out_features=768, bias=False)
            )
          )
          (3): SwinBlockSequence(
            (blocks): ModuleList(
              (0): SwinBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=768, out_features=2304, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=768, out_features=768, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=768, out_features=3072, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=3072, out_features=768, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
              (1): SwinBlock(
                (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (attn): ShiftWindowMSA(
                  (w_msa): WindowMSA(
                    (qkv): Linear(in_features=768, out_features=2304, bias=True)
                    (attn_drop): Dropout(p=0.0, inplace=False)
                    (proj): Linear(in_features=768, out_features=768, bias=True)
                    (proj_drop): Dropout(p=0.0, inplace=False)
                    (softmax): Softmax(dim=-1)
                  )
                  (drop): DropPath()
                )
                (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (ffn): FFN(
                  (activate): GELU()
                  (layers): Sequential(
                    (0): Sequential(
                      (0): Linear(in_features=768, out_features=3072, bias=True)
                      (1): GELU()
                      (2): Dropout(p=0.0, inplace=False)
                    )
                    (1): Linear(in_features=3072, out_features=768, bias=True)
                    (2): Dropout(p=0.0, inplace=False)
                  )
                  (dropout_layer): DropPath()
                )
              )
            )
          )
        )
        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
      init_cfg={'type': 'Pretrained', 'checkpoint': 'pretrained/swint-nuimages-pretrained.pth'}
      (neck): GeneralizedLSSFPN(
        (lateral_convs): ModuleList(
          (0): ConvModule(
            (conv): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
          (1): ConvModule(
            (conv): Conv2d(1152, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
        (fpn_convs): ModuleList(
          (0): ConvModule(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
          (1): ConvModule(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (activate): ReLU(inplace=True)
          )
        )
      )
      (vtransform): DepthLSSTransform(
        (dtransform): Sequential(
          (0): Conv2d(1, 8, kernel_size=(1, 1), stride=(1, 1))
          (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(8, 32, kernel_size=(5, 5), stride=(4, 4), padding=(2, 2))
          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(32, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))
          (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (8): ReLU(inplace=True)
        )
        (depthnet): Sequential(
          (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(256, 198, kernel_size=(1, 1), stride=(1, 1))
        )
        (downsample): Sequential(
          (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (4): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (7): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (8): ReLU(inplace=True)
        )
      )
    )
    (lidar): ModuleDict(
      (voxelize): Voxelization(voxel_size=[0.16, 0.16, 4], point_cloud_range=[0, -39.68, -3, 92.16, 39.68, 1], max_num_points=10, max_voxels=[120000, 160000], deterministic=True)
      (backbone): SparseEncoder(
        (conv_input): SparseSequential(
          (0): SubMConv3d()
          (1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (encoder_layers): SparseSequential(
          (encoder_layer1): SparseSequential(
            (0): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (1): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (2): SparseSequential(
              (0): SparseConv3d()
              (1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (encoder_layer2): SparseSequential(
            (0): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (1): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(32, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (2): SparseSequential(
              (0): SparseConv3d()
              (1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (encoder_layer3): SparseSequential(
            (0): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (1): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (2): SparseSequential(
              (0): SparseConv3d()
              (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
            )
          )
          (encoder_layer4): SparseSequential(
            (0): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
            (1): SparseBasicBlock(
              (conv1): SubMConv3d()
              (bn1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (conv2): SubMConv3d()
              (bn2): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
              (relu): ReLU(inplace=True)
            )
          )
        )
        (conv_out): SparseSequential(
          (0): SparseConv3d()
          (1): BatchNorm1d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
    )
  )
  (fuser): ConvFuser(
    (0): Conv2d(336, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (decoder): ModuleDict(
    (backbone): SECOND(
      (blocks): ModuleList(
        (0): Sequential(
          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (4): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (7): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (8): ReLU(inplace=True)
          (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (10): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (11): ReLU(inplace=True)
          (12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (13): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (14): ReLU(inplace=True)
          (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (16): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (17): ReLU(inplace=True)
        )
        (1): Sequential(
          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (4): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (5): ReLU(inplace=True)
          (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (7): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (8): ReLU(inplace=True)
          (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (10): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (11): ReLU(inplace=True)
          (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (13): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (14): ReLU(inplace=True)
          (15): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (16): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (17): ReLU(inplace=True)
        )
      )
    )
    init_cfg={'type': 'Kaiming', 'layer': 'Conv2d'}
    (neck): SECONDFPN(
      (deblocks): ModuleList(
        (0): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (1): Sequential(
          (0): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
      )
    )
    init_cfg=[{'type': 'Kaiming', 'layer': 'ConvTranspose2d'}, {'type': 'Constant', 'layer': 'NaiveSyncBatchNorm2d', 'val': 1.0}]
  )
  (heads): ModuleDict(
    (object): TransFusionHead(
      (loss_cls): FocalLoss()
      (loss_bbox): L1Loss()
      (loss_iou): VarifocalLoss()
      (loss_heatmap): GaussianFocalLoss()
      (shared_conv): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (heatmap_head): Sequential(
        (0): ConvModule(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activate): ReLU(inplace=True)
        )
        (1): Conv2d(128, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (class_encoding): Conv1d(10, 128, kernel_size=(1,), stride=(1,))
      (decoder): ModuleList(
        (0): TransformerDecoderLayer(
          (self_attn): MultiheadAttention(
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (multihead_attn): MultiheadAttention(
            (out_proj): Linear(in_features=128, out_features=128, bias=True)
          )
          (linear1): Linear(in_features=128, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear2): Linear(in_features=256, out_features=128, bias=True)
          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (dropout3): Dropout(p=0.1, inplace=False)
          (self_posembed): PositionEmbeddingLearned(
            (position_embedding_head): Sequential(
              (0): Conv1d(2, 128, kernel_size=(1,), stride=(1,))
              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
            )
          )
          (cross_posembed): PositionEmbeddingLearned(
            (position_embedding_head): Sequential(
              (0): Conv1d(2, 128, kernel_size=(1,), stride=(1,))
              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(128, 128, kernel_size=(1,), stride=(1,))
            )
          )
        )
      )
      (prediction_heads): ModuleList(
        (0): FFN(
          (center): Sequential(
            (0): ConvModule(
              (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
          )
          (height): Sequential(
            (0): ConvModule(
              (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv1d(64, 1, kernel_size=(1,), stride=(1,))
          )
          (dim): Sequential(
            (0): ConvModule(
              (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv1d(64, 3, kernel_size=(1,), stride=(1,))
          )
          (rot): Sequential(
            (0): ConvModule(
              (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
          )
          (vel): Sequential(
            (0): ConvModule(
              (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv1d(64, 2, kernel_size=(1,), stride=(1,))
          )
          (heatmap): Sequential(
            (0): ConvModule(
              (conv): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
              (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (activate): ReLU(inplace=True)
            )
            (1): Conv1d(64, 10, kernel_size=(1,), stride=(1,))
          )
        )
      )
    )
  )
) 